{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1bf877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140974cb",
   "metadata": {},
   "source": [
    "<h5>In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "Example:\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37079eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ae215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Setup Game\\AppData\\Local\\Temp\\ipykernel_15192\\1046822725.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\Setup Game\\AppData\\Local\\Temp\\ipykernel_15192\\1046822725.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e70593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 12)             1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ef0c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 12s 7ms/step - loss: 1.7501 - accuracy: 0.3599 - val_loss: 1.5183 - val_accuracy: 0.4351\n",
      "1/1 [==============================] - 0s 476ms/step\n",
      "Q 36+563  T 599  ☒ 660 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 556+260 T 816  ☒ 600 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 621+48  T 669  ☒ 660 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 268+735 T 1003 ☒ 101 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 599+346 T 945  ☒ 901 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 44+887  T 931  ☒ 800 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 43+395  T 438  ☒ 468 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 109+95  T 204  ☒ 200 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 247+306 T 553  ☒ 688 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 533+95  T 628  ☒ 560 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3138 - accuracy: 0.5065 - val_loss: 1.1505 - val_accuracy: 0.5738\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 590+142 T 732  ☒ 700 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 785+25  T 810  ☒ 807 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 22+221  T 243  ☒ 242 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 857+800 T 1657 ☒ 1600\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 841+452 T 1293 ☒ 1200\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 91+894  T 985  ☒ 900 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 50+88   T 138  ☒ 140 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 87+23   T 110  ☒ 10  \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 741+315 T 1056 ☒ 1102\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 40+314  T 354  ☒ 348 \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0434 - accuracy: 0.6102 - val_loss: 0.9472 - val_accuracy: 0.6441\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 931+357 T 1288 ☒ 1232\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 545+553 T 1098 ☒ 1101\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 229+30  T 259  ☒ 252 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 579+478 T 1057 ☒ 1152\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 338+350 T 688  ☒ 677 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 9+268   T 277  ☒ 272 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 86+721  T 807  ☒ 802 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 18+803  T 821  ☒ 825 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 899+80  T 979  ☒ 960 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 54+959  T 1013 ☒ 1011\n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8717 - accuracy: 0.6759 - val_loss: 0.7962 - val_accuracy: 0.7017\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 156+728 T 884  ☒ 880 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 904+576 T 1480 ☒ 1478\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 853+669 T 1522 ☒ 1513\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 399+569 T 968  ☒ 965 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 825+2   T 827  ☑ 827 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 553+58  T 611  ☒ 600 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 25+66   T 91   ☒ 88  \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 599+30  T 629  ☒ 620 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 574+87  T 661  ☒ 663 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 38+739  T 777  ☒ 770 \n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.7324 - accuracy: 0.7302 - val_loss: 0.6650 - val_accuracy: 0.7619\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 140+70  T 210  ☒ 214 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 45+860  T 905  ☒ 900 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 370+18  T 388  ☑ 388 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 3+661   T 664  ☑ 664 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 8+116   T 124  ☒ 125 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 87+29   T 116  ☒ 114 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 168+50  T 218  ☒ 215 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 43+193  T 236  ☒ 230 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 4+970   T 974  ☑ 974 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 7+725   T 732  ☑ 732 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.5985 - accuracy: 0.7820 - val_loss: 0.4921 - val_accuracy: 0.8238\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 8+726   T 734  ☑ 734 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 599+52  T 651  ☒ 659 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 322+781 T 1103 ☒ 1105\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 184+4   T 188  ☑ 188 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 690+98  T 788  ☒ 786 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 828+221 T 1049 ☒ 105 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 102+183 T 285  ☒ 284 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 72+947  T 1019 ☒ 1027\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 45+75   T 120  ☑ 120 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 644+7   T 651  ☑ 651 \n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.3742 - accuracy: 0.8737 - val_loss: 0.2727 - val_accuracy: 0.9215\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 419+120 T 539  ☑ 539 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 9+745   T 754  ☑ 754 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 902+91  T 993  ☒ 994 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 243+9   T 252  ☑ 252 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 57+77   T 134  ☑ 134 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 1+329   T 330  ☒ 320 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 99+53   T 152  ☑ 152 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 273+590 T 863  ☒ 864 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 601+0   T 601  ☑ 601 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 30+980  T 1010 ☒ 1012\n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.2129 - accuracy: 0.9421 - val_loss: 0.1713 - val_accuracy: 0.9559\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 474+83  T 557  ☑ 557 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 403+3   T 406  ☑ 406 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 119+344 T 463  ☒ 464 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 0+990   T 990  ☒ 991 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 24+930  T 954  ☑ 954 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 905+393 T 1298 ☑ 1298\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 350+535 T 885  ☑ 885 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 16+643  T 659  ☑ 659 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 175+523 T 698  ☑ 698 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 878+647 T 1525 ☑ 1525\n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.1433 - accuracy: 0.9635 - val_loss: 0.1110 - val_accuracy: 0.9754\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 2+30    T 32   ☑ 32  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 8+11    T 19   ☒ 18  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 990+577 T 1567 ☑ 1567\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 367+40  T 407  ☑ 407 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 886+59  T 945  ☑ 945 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 8+879   T 887  ☑ 887 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 923+862 T 1785 ☑ 1785\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 430+991 T 1421 ☒ 1422\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 253+8   T 261  ☑ 261 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 800+31  T 831  ☑ 831 \n",
      "\n",
      "Iteration 10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.1033 - accuracy: 0.9747 - val_loss: 0.1003 - val_accuracy: 0.9739\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 695+529 T 1224 ☑ 1224\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 51+8    T 59   ☑ 59  \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 607+15  T 622  ☑ 622 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 493+350 T 843  ☑ 843 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 243+9   T 252  ☑ 252 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 280+264 T 544  ☑ 544 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 0+871   T 871  ☑ 871 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 78+109  T 187  ☒ 186 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 20+202  T 222  ☑ 222 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 6+24    T 30   ☒ 20  \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0622 - accuracy: 0.9868 - val_loss: 0.0662 - val_accuracy: 0.9823\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 384+9   T 393  ☑ 393 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 129+367 T 496  ☑ 496 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 43+400  T 443  ☑ 443 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 64+90   T 154  ☑ 154 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 72+681  T 753  ☑ 753 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 899+626 T 1525 ☑ 1525\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 98+134  T 232  ☑ 232 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 173+272 T 445  ☑ 445 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 435+677 T 1112 ☑ 1112\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 411+344 T 755  ☑ 755 \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0648 - accuracy: 0.9837 - val_loss: 0.0338 - val_accuracy: 0.9939\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 417+6   T 423  ☑ 423 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 119+929 T 1048 ☑ 1048\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 804+577 T 1381 ☑ 1381\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 719+97  T 816  ☑ 816 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 463+0   T 463  ☑ 463 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 99+108  T 207  ☑ 207 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 463+12  T 475  ☑ 475 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 709+1   T 710  ☑ 710 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 354+3   T 357  ☑ 357 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 90+985  T 1075 ☑ 1075\n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0602 - accuracy: 0.9839 - val_loss: 0.0563 - val_accuracy: 0.9858\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 80+822  T 902  ☑ 902 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 68+795  T 863  ☑ 863 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 85+460  T 545  ☑ 545 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 22+625  T 647  ☑ 647 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 82+962  T 1044 ☑ 1044\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 3+193   T 196  ☒ 197 \n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 782+64  T 846  ☑ 846 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 93+29   T 122  ☑ 122 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 919+5   T 924  ☑ 924 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 999+1   T 1000 ☑ 1000\n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0421 - accuracy: 0.9894 - val_loss: 0.0331 - val_accuracy: 0.9922\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 67+619  T 686  ☑ 686 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 47+185  T 232  ☑ 232 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 95+586  T 681  ☑ 681 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 79+586  T 665  ☑ 665 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 220+6   T 226  ☑ 226 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 139+78  T 217  ☑ 217 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 823+554 T 1377 ☑ 1377\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 263+612 T 875  ☑ 875 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 84+59   T 143  ☑ 143 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 81+5    T 86   ☑ 86  \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0417 - accuracy: 0.9894 - val_loss: 0.0251 - val_accuracy: 0.9947\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 522+14  T 536  ☑ 536 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 607+49  T 656  ☑ 656 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 799+488 T 1287 ☑ 1287\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 904+1   T 905  ☑ 905 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 269+327 T 596  ☑ 596 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 2+34    T 36   ☑ 36  \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 69+530  T 599  ☒ 699 \n",
      "1/1 [==============================] - 0s 5ms/step\n",
      "Q 850+862 T 1712 ☑ 1712\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 723+701 T 1424 ☑ 1424\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "Q 827+83  T 910  ☑ 910 \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0366 - accuracy: 0.9898 - val_loss: 0.0639 - val_accuracy: 0.9791\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 31+515  T 546  ☑ 546 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 671+13  T 684  ☑ 684 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 30+61   T 91   ☑ 91  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 41+206  T 247  ☑ 247 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 4+287   T 291  ☑ 291 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 541+0   T 541  ☑ 541 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 738+554 T 1292 ☑ 1292\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 22+545  T 567  ☑ 567 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 574+87  T 661  ☑ 661 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 3+643   T 646  ☑ 646 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.0371 - val_accuracy: 0.9883\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 115+3   T 118  ☑ 118 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 608+88  T 696  ☑ 696 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 766+37  T 803  ☑ 803 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 81+526  T 607  ☑ 607 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 74+66   T 140  ☑ 140 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 806+15  T 821  ☑ 821 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 446+36  T 482  ☑ 482 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 276+3   T 279  ☑ 279 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 376+38  T 414  ☑ 414 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 84+616  T 700  ☑ 700 \n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0386 - accuracy: 0.9894 - val_loss: 0.0122 - val_accuracy: 0.9976\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 628+263 T 891  ☑ 891 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 4+155   T 159  ☑ 159 \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Q 172+497 T 669  ☑ 669 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 600+552 T 1152 ☑ 1152\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 695+529 T 1224 ☑ 1224\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 7+759   T 766  ☑ 766 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 895+18  T 913  ☑ 913 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 10+909  T 919  ☑ 919 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 57+466  T 523  ☑ 523 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 933+24  T 957  ☑ 957 \n",
      "\n",
      "Iteration 19\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.0153 - val_accuracy: 0.9965\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 398+841 T 1239 ☑ 1239\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 231+130 T 361  ☑ 361 \n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Q 84+641  T 725  ☑ 725 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 608+44  T 652  ☑ 652 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 875+420 T 1295 ☑ 1295\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 36+77   T 113  ☑ 113 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 348+69  T 417  ☑ 417 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 885+21  T 906  ☑ 906 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 773+75  T 848  ☑ 848 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 704+98  T 802  ☑ 802 \n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.0446 - val_accuracy: 0.9851\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 7+765   T 772  ☑ 772 \n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 834+79  T 913  ☑ 913 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 7+742   T 749  ☑ 749 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 4+43    T 47   ☑ 47  \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 7+857   T 864  ☑ 864 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 120+1   T 121  ☑ 121 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 83+241  T 324  ☑ 324 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 956+717 T 1673 ☑ 1673\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 62+4    T 66   ☑ 66  \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 4+270   T 274  ☑ 274 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0267 - accuracy: 0.9930 - val_loss: 0.0848 - val_accuracy: 0.9733\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 433+34  T 467  ☑ 467 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 598+33  T 631  ☑ 631 \n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Q 0+173   T 173  ☑ 173 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 3+952   T 955  ☑ 955 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 364+4   T 368  ☑ 368 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 42+146  T 188  ☑ 188 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 52+17   T 69   ☑ 69  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 676+764 T 1440 ☑ 1440\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 209+43  T 252  ☑ 252 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 307+738 T 1045 ☑ 1045\n",
      "\n",
      "Iteration 22\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.0111 - val_accuracy: 0.9972\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 305+90  T 395  ☑ 395 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 53+655  T 708  ☑ 708 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 923+41  T 964  ☑ 964 \n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "Q 197+28  T 225  ☑ 225 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 318+64  T 382  ☑ 382 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 68+352  T 420  ☑ 420 \n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 1+870   T 871  ☑ 871 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 46+55   T 101  ☑ 101 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 574+438 T 1012 ☑ 1012\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 80+644  T 724  ☑ 724 \n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.0076 - val_accuracy: 0.9987\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 662+582 T 1244 ☑ 1244\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 581+432 T 1013 ☑ 1013\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Q 656+520 T 1176 ☑ 1176\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 36+196  T 232  ☑ 232 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 35+394  T 429  ☑ 429 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 50+34   T 84   ☑ 84  \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 3+109   T 112  ☑ 112 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 83+59   T 142  ☑ 142 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 628+263 T 891  ☑ 891 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 541+78  T 619  ☑ 619 \n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.0315 - accuracy: 0.9909 - val_loss: 0.0236 - val_accuracy: 0.9930\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 647+718 T 1365 ☑ 1365\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 402+92  T 494  ☑ 494 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 92+967  T 1059 ☑ 1059\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 614+302 T 916  ☑ 916 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 79+170  T 249  ☑ 249 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 80+46   T 126  ☑ 126 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 5+143   T 148  ☑ 148 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 585+68  T 653  ☑ 653 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 1+40    T 41   ☑ 41  \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 762+4   T 766  ☑ 766 \n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0189 - val_accuracy: 0.9946\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 623+63  T 686  ☑ 686 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 641+270 T 911  ☑ 911 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 64+984  T 1048 ☑ 1048\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 67+55   T 122  ☑ 122 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 1+422   T 423  ☑ 423 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 432+856 T 1288 ☑ 1288\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 97+620  T 717  ☑ 717 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 336+6   T 342  ☑ 342 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 742+882 T 1624 ☑ 1624\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 20+169  T 189  ☑ 189 \n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 97+970  T 1067 ☑ 1067\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 95+719  T 814  ☑ 814 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 647+88  T 735  ☑ 735 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 641+270 T 911  ☑ 911 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 600+552 T 1152 ☑ 1152\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 574+94  T 668  ☑ 668 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 337+67  T 404  ☑ 404 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 284+87  T 371  ☑ 371 \n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Q 0+700   T 700  ☑ 700 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 98+978  T 1076 ☑ 1076\n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0227 - val_accuracy: 0.9934\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 19+402  T 421  ☑ 421 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 338+336 T 674  ☑ 674 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 692+2   T 694  ☑ 694 \n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "Q 665+73  T 738  ☑ 738 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 503+1   T 504  ☑ 504 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 927+5   T 932  ☑ 932 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 406+40  T 446  ☑ 446 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 48+91   T 139  ☑ 139 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 4+587   T 591  ☑ 591 \n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Q 387+761 T 1148 ☑ 1148\n",
      "\n",
      "Iteration 28\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9990\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 35+724  T 759  ☑ 759 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 110+26  T 136  ☑ 136 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 40+781  T 821  ☑ 821 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 70+21   T 91   ☑ 91  \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 2+981   T 983  ☑ 983 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 8+726   T 734  ☑ 734 \n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Q 997+948 T 1945 ☑ 1945\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 877+87  T 964  ☑ 964 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 79+561  T 640  ☑ 640 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 76+879  T 955  ☑ 955 \n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.0299 - accuracy: 0.9914 - val_loss: 0.0133 - val_accuracy: 0.9964\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 42+675  T 717  ☑ 717 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 787+74  T 861  ☑ 861 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 731+3   T 734  ☑ 734 \n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Q 84+474  T 558  ☑ 558 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 231+1   T 232  ☑ 232 \n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Q 662+579 T 1241 ☑ 1241\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Q 683+386 T 1069 ☑ 1069\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 21+796  T 817  ☑ 817 \n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Q 654+383 T 1037 ☑ 1037\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "Q 398+1   T 399  ☒ 499 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3998db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27869594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
